1.	获取url

    a)	使用googlesearch库，根据初始化的病毒名库，分别对news和blog类型url进行获取。过滤后共含有3855个url链接

2.	获取作者，发布时间信息

    a)	对url的域名进行提取，并使用BeautifulSoup库解析网页html格式，对其中50个筛选的主要域名编写独立的爬虫代码，提取其作者和时间信息，根据域名判断其来源类型。
    
3.	获取待分析文本

    a)	使用newspaper库的Article方法对每个url内容进行解析，经测试该库不能有效提取作者时间等信息，但对于title和内容文本可以有效的提取。

    b)	对文本内容按句子划分，判断是否出现两个以上病毒名，并保存到本地

4.	根据正则方法匹配同族病毒，并更新初始化的病毒库内容。统计得到共计62族病毒

5.	分析病毒出现的年份。

    a)	根据已有的62族病毒，分别解析各url的text内容，对各族病毒内容中出现的年份信息进行统计，出现频率最高的为病毒出现的年份。与已知信息对比后无误。录入初始化病毒库

6.	Nlp分析各族病毒关系并绘图

    a)	对每族病毒的url所解析的text内容中出现的其他族病毒的句子进行本地保存。

    b)	共计3700句

    c)	选取其中200句进行人工判别是否含起源关系，作为训练样本。

    d)	对训练样本中出现的每个词计算其信息增益熵值
        
            信息熵计算公式：

<img src = "https://github.com/ly358863521/malware-search/blob/master/ScreenShots/BY%40DRO%5B4LXYW%7B9C7TMW6%24RC.png" width ="200"  />
        
            信息条件熵公式：
        
<img src = "https://github.com/ly358863521/malware-search/blob/master/ScreenShots/T9UX3)WY9PO%25D4L3%60S%604%5D%24U.png" width = "200" />
        
            信息增益计算公式：

<img src = "https://github.com/ly358863521/malware-search/blob/master/ScreenShots/J%2531%24%60E5W1Q%7B~K%7BZT)H%5BBQ6.png" width = "400" />
        
        选取其中信息增益较高的词并人工筛选得到初始化关键词列表：['new','same','evolution','likely','common','offspring','later','known','variant','beyond','faster','than','while','followed','like','from','version','fusion']
        
    e) 使用nltk中的wordnet库对特征参数关键词扩展同义词列表，并输出到文件wordnet.txt中，扩展其特征参数。
    
    f)	使用nltk库的pos_tag方法获取关键词和源病毒名和其他病毒名在句子中的词性以及位置，根据词性和位置信息再次对特征参数进行扩展。
    
    g)	选择SVM模型，对各参数进行调优，对训练样本进行拟合，得分0.97
    
    h)	之后对所有样本进行关系预测分类，并本地保存预测结果为1的内容。
    
    i)	对预测结果为1的结果内容人工判断筛选一遍。
     
    j)	用networkx绘有向图，并根据年份信息判断起源关系中的先后顺序。
