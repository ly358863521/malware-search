from GoogleNews import GoogleNews
import newspaper
from newspaper import Article
import requests
from search_word import search_word
from bs4 import BeautifulSoup
import re
import pandas as pd
from regex_ import regex
# get alias
df = pd.read_excel('Malware_name.xlsx')
for i in range(1,62):
    malware_name = df.values[:,0]
    readDir = "../url_filter/"+str(i)+".txt"
    write_alias = open("../text/"+str(i)+"_alias_name.txt","a",encoding = "utf-8")
    f = open(readDir,"r")
    url_num = 0
    for url in f:
        url = url.strip('\n')
        print(i,url_num,url)
        url_num+=1
        try:
            news = Article(url, language='en')
            news.download()
            news.parse()
            for j in search_word(news.text,malware_name,spl=['.','\n'],n=1):
                write_alias.write(regex(j),'\n')
        except newspaper.article.ArticleException as e:
            print(e)
    write_alias.close()