from GoogleNews import GoogleNews
import newspaper
from newspaper import Article
import requests
from search_word import search_word
from bs4 import BeautifulSoup
import re
import pandas as pd
from regex_ import regex
df = pd.read_excel('Malware_name.xlsx')
# get relation text
for i in range(1,62):
    malware_name = df[df['family'] ==i].values[:,0]
    other = df[df['family'] !=i].values[:,0]
    readDir = "../url_filter/"+str(i)+".txt"
    write_alias = open("../text/"+str(i)+"_alias_text.txt","a",encoding = "utf-8")
    write_relation = open("../text/"+str(i)+"_relation_text.txt","a",encoding = "utf-8")
    f = open(readDir,"r")
    url_num = 0
    for url in f:
        url = url.strip('\n')
        print(i,url_num,url)
        url_num+=1
        try:
            news = Article(url, language='en')
            news.download()
            news.parse()
            for j in search_word(news.text,malware_name,spl=['.','\n'],n=2):
                write_alias.write(j+'\n')
            for k in search_word(news.text,other,spl = ['.','\n'],n = 1):
                write_relation.write(k +'\n')
        except newspaper.article.ArticleException as e:
            print(e)
    write_alias.close()
    write_relation.close()
